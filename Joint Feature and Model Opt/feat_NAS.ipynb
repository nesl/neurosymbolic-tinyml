{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e9cc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import glob\n",
    "import sys\n",
    "import numpy\n",
    "import tsfel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto() \n",
    "config.gpu_options.allow_growth = True  \n",
    "config.log_device_placement = True  \n",
    "sess2 = tf.compat.v1.Session(config=config)\n",
    "set_session(sess2) \n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from tcn import compiled_tcn\n",
    "from mango.tuner import Tuner\n",
    "from keras_flops import get_flops\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import random\n",
    "from hardware_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55dc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAS_EPOCHS = 100 #NAS epochs\n",
    "EPOCHS = 150 #model epochs\n",
    "device = \"NUCLEO_L4R5ZI_P\" #hardware name\n",
    "dirpath='FeatNN_Mbed_Prog/' #mbed program directory\n",
    "model_name = \"featNN\"+device+\"_\"+\".h5\"\n",
    "os.system(\"mkdir -p trained_models/\")\n",
    "platform_connected = False #HIL or proxy\n",
    "\n",
    "log_file_name = 'log_NAS_featNN'+\"_\"+device+'.csv' #log file for NAS\n",
    "if os.path.exists(log_file_name):\n",
    "    os.remove(log_file_name)\n",
    "row_write = ['score', 'accuracy','SRAM','Flash','Latency',\n",
    "             'nb_filters','kernel_size','dilations','nb_stacks','use_skip_connections',\n",
    "            'use_iqr','use_max','use_Median','use_variance','use_MAD','use_Abs_energy',\n",
    "            'use_entropy','use_ppd','use_fft','use_ff','use_mps']\n",
    "with open(log_file_name, 'a', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    csvwriter.writerow(row_write)\n",
    "if os.path.exists(log_file_name[0:-4]+'.p'):\n",
    "    os.remove(log_file_name[0:-4]+'.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc04f645",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56f8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_sig = np.loadtxt('UCI HAR Dataset/train/Inertial Signals/total_acc_x_train.txt', dtype='float32')\n",
    "X_train_sig = pd.DataFrame(np.hstack(x_train_sig), columns=[\"total_acc_x\"])\n",
    "Y_train = np.loadtxt('UCI HAR Dataset/train/y_train.txt')\n",
    "Y_train = Y_train-1\n",
    "Y_train = to_categorical(Y_train.reshape((len(Y_train),1)),num_classes=len(set(Y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c01f0",
   "metadata": {},
   "source": [
    "## Training and NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_NN(nb_filters=6,kernel_size=32,dilations=[1,2,4,8,16,32,64,128],\n",
    "                 nb_stacks=1, use_skip_connections = True,\n",
    "                use_iqr = True, use_max = True, use_Median= True,\n",
    "                use_variance = True, use_MAD = True,\n",
    "                use_Abs_energy = True, use_entropy = True,\n",
    "                use_ppd = True, use_fft = True, use_ff = True, use_mps = True):\n",
    "    \n",
    "    feat_mask = [0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    stat_feat_list = []\n",
    "    temporal_feat_list = []\n",
    "    spectral_feat_list = []\n",
    "    \n",
    "    if(use_fft==True):\n",
    "        spectral_feat_list.append('FFT mean coefficient')\n",
    "        feat_mask[0] = 1\n",
    "    if(use_ff==True):\n",
    "        spectral_feat_list.append('Fundamental frequency') \n",
    "        feat_mask[1] = 1\n",
    "    if(use_mps==True):\n",
    "        spectral_feat_list.append('Max power spectrum')  \n",
    "        feat_mask[2] = 1\n",
    "    if(use_iqr==True):\n",
    "        stat_feat_list.append('Interquartile range')\n",
    "        feat_mask[3] = 1\n",
    "    stat_feat_list.append('Mean')\n",
    "    feat_mask[4] = 1\n",
    "    if(use_max==True):\n",
    "        stat_feat_list.append('Max')\n",
    "        feat_mask[5] = 1\n",
    "    if(use_Median==True):\n",
    "        stat_feat_list.append('Median')\n",
    "        feat_mask[6] = 1\n",
    "    if(use_variance==True):\n",
    "        stat_feat_list.append('Variance')  \n",
    "        feat_mask[7] = 1\n",
    "    if(use_MAD==True):\n",
    "        stat_feat_list.append('Mean absolute deviation')\n",
    "        feat_mask[8] = 1\n",
    "    if(use_Abs_energy==True):\n",
    "        temporal_feat_list.append('Absolute energy')\n",
    "        feat_mask[9] = 1\n",
    "    if(use_entropy==True):\n",
    "        temporal_feat_list.append('Entropy') \n",
    "        feat_mask[10] = 1\n",
    "    if(use_ppd==True):\n",
    "        temporal_feat_list.append('Peak to peak distance')  \n",
    "        feat_mask[11] = 1\n",
    "    \n",
    "    feat_mask = '{'+str(feat_mask)[1:-1]+'}'\n",
    " \n",
    "    cgf_file = tsfel.get_features_by_domain()\n",
    "    for item in cgf_file['statistical'].keys():\n",
    "        if(item not in stat_feat_list):\n",
    "            cgf_file['statistical'][item]['use'] = 'no'\n",
    "    for item in cgf_file['spectral'].keys():\n",
    "        if(item=='FFT mean coefficient'):\n",
    "            cgf_file['spectral'][item]['parameters']['nfreq'] = 64\n",
    "        if(item not in spectral_feat_list):\n",
    "            cgf_file['spectral'][item]['use'] = 'no'\n",
    "    for item in cgf_file['temporal'].keys():\n",
    "        if(item not in temporal_feat_list):\n",
    "            cgf_file['temporal'][item]['use'] = 'no'\n",
    "\n",
    "    X_train = tsfel.time_series_features_extractor(cgf_file, X_train_sig, fs=50, window_size=128)\n",
    "    ################################################################################\n",
    "    \n",
    "    print(nb_filters,kernel_size,dilations,nb_stacks, use_skip_connections)\n",
    "    training_flag = 0\n",
    "    score = -5.0\n",
    "    accuracy = -1.0\n",
    "    inputs = layers.Input((X_train.shape[1]))\n",
    "    x = inputs\n",
    "    x = layers.Reshape((X_train.shape[1],1))(x)\n",
    "    x = TCN(return_sequences=False,\n",
    "                     nb_filters=nb_filters,\n",
    "                     kernel_size=kernel_size,\n",
    "                     dilations=dilations,\n",
    "                     nb_stacks=nb_stacks,\n",
    "                     use_skip_connections=use_skip_connections)(x)\n",
    "    outputs = layers.Dense(Y_train.shape[1], activation=\"softmax\", name=\"pred\")(x)\n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=opt,metrics=['accuracy'])\n",
    "    checkpoint = ModelCheckpoint(model_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "    ################################################################################\n",
    "    if(platform_connected == False):\n",
    "        Latency = get_flops(model, batch_size=1) #latency proxy\n",
    "        RAM = get_model_memory_usage(batch_size=1, model=model) #SRAM proxy\n",
    "        if(quantization==True):\n",
    "            RAM = RAM/8.0\n",
    "        Flash =  get_model_flash_usage(model,'g_featnn_model_data',quantization=quantization) #flash proxy\n",
    "        if(RAM < maxRAM and Flash < maxFlash):\n",
    "            training_flag = 1\n",
    "        else:\n",
    "            training_flag = 0\n",
    "            score = -5.0\n",
    "            accuracy = -1.0\n",
    "    else:\n",
    "        RAM, Flash, Latency, err_flag = platform_in_the_loop_controller(model,'g_featnn_model_data', \n",
    "                                            device,X_train.shape[1],128,50,feat_mask,\n",
    "                                            dir_path=dirpath)\n",
    "        if(RAM!=-1 and Flash!=-1 and Latency!=-1):\n",
    "            training_flag = 1\n",
    "        else:\n",
    "            training_flag = 0\n",
    "            score = -5.0\n",
    "            accuracy = -1.0\n",
    "    ################################################################################\n",
    "    if(training_flag == 1):\n",
    "        history = model.fit(x=X_train, y=Y_train,validation_split=0.1,\n",
    "              epochs=EPOCHS,callbacks=[checkpoint],shuffle=True,verbose=1)\n",
    "        accuracy = checkpoint.best\n",
    "        score = accuracy + 0.01*((RAM/maxRAM) + (Flash/maxFlash)) +  0.01*(Latency/1e6)\n",
    "    \n",
    "    row_write = [score, accuracy,RAM,Flash,Latency,\n",
    "             nb_filters,kernel_size,dilations,nb_stacks,use_skip_connections,\n",
    "            use_iqr,use_max,use_Median,use_variance,use_MAD,use_Abs_energy,\n",
    "            use_entropy,use_ppd,use_fft,use_ff,use_mps]    \n",
    "    print('Design choice:',row_write)\n",
    "    with open(log_file_name, 'a', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(row_write)     \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f28f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_res(data, file_name):\n",
    "    pickle.dump( data, open( file_name, \"wb\" ) )\n",
    "    \n",
    "min_layer = 3\n",
    "max_layer = 8\n",
    "a_list = [1,2,4,8,16,32,64,128]\n",
    "all_combinations = []\n",
    "dil_list = []\n",
    "for r in range(len(a_list) + 1):\n",
    "    combinations_object = itertools.combinations(a_list, r)\n",
    "    combinations_list = list(combinations_object)\n",
    "    all_combinations += combinations_list\n",
    "all_combinations = all_combinations[1:]\n",
    "for item in all_combinations:\n",
    "    if(len(item) >= min_layer and len(item) <= max_layer):\n",
    "        dil_list.append(list(item))\n",
    "\n",
    "param_dict = {\n",
    "    'nb_filters': range(3,64),\n",
    "    'nb_stacks': [1,2,3],\n",
    "    'kernel_size': range(3,16),\n",
    "    'use_skip_connections': [True, False],\n",
    "    'dilations': dil_list,\n",
    "    'use_iqr' : [True, False],\n",
    "    'use_max': [True, False],\n",
    "    'use_Median': [True, False],\n",
    "    'use_variance': [True, False],\n",
    "    'use_MAD': [True, False],\n",
    "    'use_Abs_energy': [True, False],\n",
    "    'use_entropy': [True, False],\n",
    "    'use_ppd': [True, False],\n",
    "    'use_fft': [True, False],\n",
    "    'use_ff': [True, False],\n",
    "    'use_mps': [True, False]\n",
    "}\n",
    "\n",
    "def objfunc(args_list):\n",
    "\n",
    "    objective_evaluated = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for hyper_par in args_list:\n",
    "        nb_filters = hyper_par['nb_filters']\n",
    "        nb_stacks = hyper_par['nb_stacks']\n",
    "        kernel_size = hyper_par['kernel_size']\n",
    "        use_skip_connections = hyper_par['use_skip_connections']\n",
    "        dilations = hyper_par['dilations']\n",
    "        \n",
    "        use_iqr = hyper_par['use_iqr']\n",
    "        use_max = hyper_par['use_max']\n",
    "        use_Median = hyper_par['use_Median']\n",
    "        use_variance = hyper_par['use_variance']        \n",
    "        use_MAD = hyper_par['use_MAD']\n",
    "        use_Abs_energy = hyper_par['use_Abs_energy']            \n",
    "        use_entropy = hyper_par['use_entropy']\n",
    "        use_ppd = hyper_par['use_ppd']    \n",
    "        use_fft = hyper_par['use_fft']            \n",
    "        use_ff = hyper_par['use_ff']\n",
    "        use_mps = hyper_par['use_mps'] \n",
    "            \n",
    "        objective = objective_NN(nb_filters=nb_filters,kernel_size=kernel_size,dilations=dilations,\n",
    "                 nb_stacks=nb_stacks, use_skip_connections = use_skip_connections, \n",
    "                use_iqr = use_iqr, use_max = use_max, use_Median= use_Median,\n",
    "                use_variance = use_variance, use_MAD = use_MAD,\n",
    "                use_Abs_energy = use_Abs_energy, use_entropy = use_entropy,\n",
    "                use_ppd = use_ppd, use_fft = use_fft, use_ff = use_ff, use_mps = use_mps)\n",
    "        objective_evaluated.append(objective)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print('objective:', objective, ' time:',end_time-start_time)\n",
    "        \n",
    "    return objective_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee25617",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_Dict = dict()\n",
    "conf_Dict['batch_size'] = 1 \n",
    "conf_Dict['num_iteration'] = NAS_EPOCHS\n",
    "conf_Dict['initial_random']= 5\n",
    "tuner = Tuner(param_dict, objfunc,conf_Dict)\n",
    "all_runs = []\n",
    "results = tuner.maximize()\n",
    "all_runs.append(results)\n",
    "save_res(all_runs,log_file_name[0:-4]+'.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790dff2",
   "metadata": {},
   "source": [
    "## Train the best model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf6838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_ar = [results['best_params']['use_skip_connections'],\n",
    "           results['best_params']['use_iqr'],\n",
    "           results['best_params']['use_max'],\n",
    "           results['best_params']['use_Median'],\n",
    "           results['best_params']['use_variance'],\n",
    "           results['best_params']['use_MAD'],\n",
    "           results['best_params']['use_Abs_energy'],\n",
    "           results['best_params']['use_entropy'],\n",
    "           results['best_params']['use_ppd'],\n",
    "           results['best_params']['use_fft'],\n",
    "           results['best_params']['use_ff'],\n",
    "           results['best_params']['use_mps']]\n",
    "\n",
    "nb_filters=results['best_params']['nb_filters']\n",
    "kernel_size=results['best_params']['kernel_size']\n",
    "dilations=results['best_params']['dilations']\n",
    "nb_stacks=results['best_params']['nb_stacks']\n",
    "use_skip_connections = bool_ar[0]\n",
    "use_iqr = bool_ar[1]\n",
    "use_max = bool_ar[2]\n",
    "use_Median= bool_ar[3]\n",
    "use_variance = bool_ar[4]\n",
    "use_MAD = bool_ar[5]\n",
    "use_Abs_energy = bool_ar[6]\n",
    "use_entropy = bool_ar[7]\n",
    "use_ppd = bool_ar[8] \n",
    "use_fft = bool_ar[9]\n",
    "use_ff = bool_ar[10] \n",
    "use_mps = bool_ar[11]\n",
    "    \n",
    "stat_feat_list = []\n",
    "temporal_feat_list = []\n",
    "spectral_feat_list = []\n",
    "stat_feat_list.append('Mean')\n",
    "if(use_iqr==True):\n",
    "    stat_feat_list.append('Interquartile range')\n",
    "if(use_max==True):\n",
    "    stat_feat_list.append('Max')\n",
    "if(use_Median==True):\n",
    "    stat_feat_list.append('Median')\n",
    "if(use_variance==True):\n",
    "    stat_feat_list.append('Variance')    \n",
    "if(use_MAD==True):\n",
    "    stat_feat_list.append('Mean absolute deviation')\n",
    "if(use_Abs_energy==True):\n",
    "    temporal_feat_list.append('Absolute energy')\n",
    "if(use_entropy==True):\n",
    "    temporal_feat_list.append('Entropy') \n",
    "if(use_ppd==True):\n",
    "    temporal_feat_list.append('Peak to peak distance')     \n",
    "if(use_fft==True):\n",
    "    spectral_feat_list.append('FFT mean coefficient')\n",
    "if(use_ff==True):\n",
    "    spectral_feat_list.append('Fundamental frequency') \n",
    "if(use_mps==True):\n",
    "    spectral_feat_list.append('Max power spectrum')      \n",
    "\n",
    "cgf_file = tsfel.get_features_by_domain()\n",
    "for item in cgf_file['statistical'].keys():\n",
    "    if(item not in stat_feat_list):\n",
    "        cgf_file['statistical'][item]['use'] = 'no'\n",
    "for item in cgf_file['spectral'].keys():\n",
    "    if(item not in spectral_feat_list):\n",
    "        cgf_file['spectral'][item]['use'] = 'no'\n",
    "for item in cgf_file['temporal'].keys():\n",
    "    if(item not in temporal_feat_list):\n",
    "        cgf_file['temporal'][item]['use'] = 'no'\n",
    "\n",
    "X_train = tsfel.time_series_features_extractor(cgf_file, X_train_sig, fs=50, window_size=128)\n",
    "inputs = layers.Input((X_train.shape[1]))\n",
    "x = inputs\n",
    "x = layers.Reshape((X_train.shape[1],1))(x)\n",
    "x = TCN(return_sequences=False,\n",
    "                 nb_filters=nb_filters,\n",
    "                 kernel_size=kernel_size,\n",
    "                 dilations=dilations,\n",
    "                 nb_stacks=nb_stacks,\n",
    "                 use_skip_connections=use_skip_connections)(x)\n",
    "outputs = layers.Dense(Y_train.shape[1], activation=\"softmax\", name=\"pred\")(x)\n",
    "model = Model(inputs = inputs, outputs = outputs)\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "          optimizer=opt,metrics=['accuracy'])\n",
    "checkpoint = ModelCheckpoint(model_name, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(x=X_train, y=Y_train,validation_split=0.1,\n",
    "      epochs=EPOCHS,callbacks=[checkpoint],shuffle=True,verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39746dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(model_name,custom_objects={'TCN':TCN})\n",
    "x_test_sig = np.loadtxt('UCI HAR Dataset/test/Inertial Signals/total_acc_x_test.txt', dtype='float32')\n",
    "X_test_sig = pd.DataFrame(np.hstack(x_test_sig), columns=[\"total_acc_x\"])\n",
    "Y_test = np.loadtxt('UCI HAR Dataset/test/y_test.txt')\n",
    "Y_test = Y_test-1\n",
    "Y_test = to_categorical(Y_test.reshape((len(Y_test),1)),num_classes=len(set(Y_test)))\n",
    "X_test = tsfel.time_series_features_extractor(cgf_file, X_test_sig, fs=50, window_size=128)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
